import requests
import json
import datetime
import os.path
import requests
from bs4 import BeautifulSoup
import time
import sys
from evaluator import Evaluator
from metrics import Metrics
from filewriter import FileWriter

test_set_path = "testSet"
training_set_path = "trainingSet"
topics = 200
passes = 1
test_set_limit = 200
threshold_start = 1
threshold_end = 10
base_search_url = "https://www.ncbi.nlm.nih.gov/pubmed?linkname=pubmed_pubmed&from_uid="
thresholds = []
metrics_obj_list = []

#Data list generated by https://curl.trillworks.com/. Removed non-related entries.
def get_post_data(page = 1):
    data = [
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_Facets.FacetsUrlFrag', 'filters='),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_Facets.FacetSubmitted', 'false'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.sPresentation', 'medline'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.sSort', 'none'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.sPageSize', '200'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.Presentation', 'medline'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.PageSize', '200'),
      ('EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_Pager.CurrPage', page),
      ('CollectionStartIndex', '1'),
      ('CitationManagerStartIndex', '1'),
      ('EntrezSystem2.PEntrez.DbConnector.Db', 'pubmed'),
      ('EntrezSystem2.PEntrez.DbConnector.LastDb', 'pubmed'),
      ('EntrezSystem2.PEntrez.DbConnector.LastQueryKey', '1'),
      ('EntrezSystem2.PEntrez.DbConnector.Cmd', 'displaychanged'),
      ('p$a', 'EntrezSystem2.PEntrez.PubMed.Pubmed_ResultsPanel.Pubmed_DisplayBar.sPresentation'),
      ('p$l', 'EntrezSystem2'),
      ('p$st', 'pubmed'),
    ]

    return data

def getTime():
    return str(datetime.datetime.time(datetime.datetime.now()))

def tlog(msg):
    print("["+getTime()+"] "+msg)

def printProgressBar(progress, total):
    prog_bar = ""
    padding = ""
	#int(100*ratio) so we get something like e.g. int(0.733435*100) = 73, halved, to print 50 '=' maximum
    prog = int(int(100*progress / total)*0.5)
    for i in range(prog):
        prog_bar += "="
    for i in range(50-prog):
        padding += " "
    if(int(progress/total) < 1):
        percentage = int(100*progress/total)
        print("\t["+prog_bar+padding+"] " + str(percentage)+"%", end="\r")
        sys.stdout.flush()
    else:
        print("\t["+prog_bar+padding+"] 100%")
        print()

def split_lines(text):
    return iter(text.splitlines())

def parse_docs(response):
    response = response.content
    docs = []
    doc = {}
    pmid = ""
    mesh = []

    for line in split_lines(response):
        text = str(line.decode("utf-8"))
        if text.startswith("PMID-"):
            text = text.replace("PMID-", "")

            #Add previous mesh to previous doc
            if len(mesh) != 0:
                docs.append({"pmid":pmid, "meshMajor":mesh})
                mesh = []

            #Set new doc pmid
            pmid = text.strip()
            mesh = []

        elif text.startswith("MH  -"):
            text = text.replace("MH  -", "").strip().split("/")[0]
            if text.startswith("*"):
                text = text[1:]

            mesh.append(text)

    return docs

session = requests.Session()

start_time = getTime()

training_set_json = json.load(open(training_set_path))["documents"]

if test_set_limit !=-1:
    test_set = json.load(open(test_set_path))["documents"][0:test_set_limit]
else:
    test_set = json.load(open(test_set_path))["documents"]

test_set_pmids = [doc["pmid"] for doc in test_set]
tlog("Test set read.")

fw = FileWriter()

for i in range(threshold_start, threshold_end+1):
    thresholds.append(i)
    metrics_obj_list.append(Metrics())

eval = Evaluator()

doc_results = {}

results_file = open("results.json","r")
pmid_results = json.load(results_file)

result_documents_file = open("result_documents.json","r")
result_documents = json.load(result_documents_file)

i=0
counter = 0
if os.path.exists("post_pmra_results.json"):
    doc_results = json.load(open("post_pmra_results.json", "r"))
else:
    for doc in test_set:
        counter += 1
        session.cookies.clear()
        try:
            session.get("https://www.ncbi.nlm.nih.gov/pubmed?linkname=pubmed_pubmed&from_uid="+doc["pmid"])
        except Exception as e:
            print(e)
            print("Connection error, waiting for two minutes.")
            time.sleep(120)
            session.get("https://www.ncbi.nlm.nih.gov/pubmed?linkname=pubmed_pubmed&from_uid="+doc["pmid"])

        results = []
        page = 1
        done = False

        while not done:
            time.sleep(2)
            try:
                docs = parse_docs(session.post('https://www.ncbi.nlm.nih.gov/pubmed', data=get_post_data(page)))
            except Exception as e:
                print(e)
                print("Connection error, waiting for two minutes.")
                time.sleep(120)
                docs = parse_docs(session.post('https://www.ncbi.nlm.nih.gov/pubmed', data=get_post_data(page)))

            if len(docs) == 0:
                done = True
            else:
                results.extend(docs)
                page += 1

        test_results = pmid_results[doc["pmid"]]

        all_gud = True
        j = 0
        for i in range(1,11):
            if results[i]["pmid"] != test_results[j]:
                print("Not same. ", results[i]["pmid"], test_results[j], i, j)
                print("Query: ", doc["pmid"])
                print("Length of results: ", len(results))
                print(results[1]["pmid"], results[2]["pmid"], results[3]["pmid"], results[4]["pmid"], results[5]["pmid"], results[6]["pmid"], results[7]["pmid"], results[8]["pmid"], results[9]["pmid"], results[10]["pmid"])
                print(test_results[0], test_results[1], test_results[2], test_results[3], test_results[4], test_results[5], test_results[6], test_results[7], test_results[8], test_results[9])
                all_gud = False
                break
            j += 1

        if not all_gud:
            print("Dayum son")

        doc_results[doc["pmid"]] = results

        printProgressBar(counter, len(test_set))

    total_results = open("post_pmra_results.json", "w")
    total_results.write(json.dumps(doc_results))
    tlog("Wrote results to disk.")

training_set = {}
for doc in training_set_json:
    training_set[doc["pmid"]] = 1

counter = 0
for doc in test_set:
    results = []
    temp_results = doc_results[doc["pmid"]]

    for temp_doc in temp_results:
        if temp_doc["pmid"] in training_set:
            counter += 1
            results.append(temp_doc)

    for k in range(0, len(thresholds)):
        threshold = thresholds[k]

        eval.query(results[1:threshold+1], doc)
        eval.calculate()

        metrics_obj_list[k].updateMacroAverages(eval)

    i+=1
    printProgressBar(i, len(test_set))

print("Docs in training set: ", counter)

for obj in metrics_obj_list:
    obj.calculate(len(test_set))

tlog("Done getting results. Writing to files.")
fw.writeToFiles(metrics_obj_list, thresholds)

tlog("Done.")
